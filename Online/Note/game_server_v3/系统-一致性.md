
<!-- TOC -->

- [分布式系统基本概念](#分布式系统基本概念)
    - [CAP](#cap)
    - [C](#c)
        - [模型](#模型)
        - [方案](#方案)
    - [A](#a)
        - [方案](#方案-1)
    - [P](#p)
        - [BASE](#base)
        - [方案](#方案-2)
- [高并发系统的设计](#高并发系统的设计)
    - [系统拆分](#系统拆分)
    - [缓存](#缓存)
    - [消息队列](#消息队列)
    - [分库分表](#分库分表)
    - [读写分离](#读写分离)
- [分布式](#分布式)
    - [分布式缓存](#分布式缓存)
    - [分布式锁](#分布式锁)
    - [分布式事务](#分布式事务)
- [Q](#q)
    - [如何保证缓存和数据库数据的一致性？](#如何保证缓存和数据库数据的一致性)
    - [如何实现一致性？](#如何实现一致性)
    - [实现一致性示例](#实现一致性示例)
        - [统一递交](#统一递交)
        - [日志回溯](#日志回溯)
        - [冲突避免](#冲突避免)

<!-- /TOC -->

<div STYLE="page-break-after: always;"></div>

# 分布式系统基本概念

## CAP
如果系统发生“分区”，我们要考虑选择 CP【ZooKeeper】 还是 AP【Eureka】。如果系统没有发生“分区”的话，我们要思考如何保证 CA 。

- 一致性（Consistency） ：等同于所有节点访问同一份最新的数据副本，或者说同一数据在不同节点上的副本在同一逻辑时钟应当是相同的内容。
- 可用性（Availability）：每次请求都能获取到非错的响应，以及尽量保证低延迟，但是不保证获取的数据为最新数据。
- 分区容错性（Partition tolerance）：以实际效果而言，分区相当于对通信的时限要求。要求任意节点故障时，系统仍然可以对外服务。

## C

### 模型
弱一致性：用户读到某一操作对系统特定数据的更新需要一段时间，我们称这段时间为“不一致性窗口”。
最终一致性：是弱一致性的一种特例，保证用户**最终（即窗口尽量长）**能够读取到某操作对系统特定数据的更新。

### 方案
1. 分布式事务：两段提交
2. 分布式锁
3. 消息队列、消息持久化、重试、幂等操作
4. Raft / Paxos 等一致性算法

## A
### 方案
1. 负载均衡：尽力将网络流量平均分发到多个服务器上，以提高系统整体的响应速度和可用性。
1. 降级：当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。
1. 熔断：对于目标服务的请求和调用大量超时或失败，这时应该熔断该服务的所有调用，并且对于后续调用应直接返回，从而快速释放资源。确保在目标服务不可用的这段时间内，所有对它的调用都是立即返回的、不会阻塞的，等到目标服务好转后进行接口恢复。
1. 流量控制：流量控制可以有效的防止由于网络中瞬间的大量数据对网络带来的冲击，保证用户网络高效而稳定的运行，类似于TCP拥塞控制方法。
1. 异地多活：在不同地区维护不同子系统，并保证子系统的可用性

## P
分区容错无法避免，因此可以认为 CAP 的 P 总是成立。CAP 定理告诉我们，剩下的 C 和 A 无法同时做到

### BASE
BASE 是 Basically Available（基本可用）、Soft-state（软状态） 和 Eventually Consistent（最终一致性） 三个短语的缩写，是 CAP 理论中 AP 方案的延伸

- 基本可用
基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用。什么叫允许损失部分可用性呢？
    - 响应时间上的损失: 正常情况下，处理用户请求需要 0.5s 返回结果，但是由于系统出现故障，处理用户请求的时间变为 3 s。
    - 系统功能上的损失：正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用。

- 软状态
软状态软状态指允许系统中的数据存在中间状态（CAP 理论-数据不一致），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。

- 最终一致性
最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。

### 方案
实现最终一致性的具体方式
- 读时修复 : 在读取数据时，检测数据的不一致，进行修复。比如 Cassandra 的 Read Repair 实现，具体来说，在向 Cassandra 系统查询数据的时候，如果检测到不同节点的副本数据不一致，系统就自动修复数据。
- 写时修复 : 在写入数据，检测数据的不一致时，进行修复。比如 Cassandra 的 Hinted Handoff 实现。具体来说，Cassandra 集群的节点之间远程写数据的时候，如果写失败 就将数据缓存下来，然后定时重传，修复数据的不一致性。
- 异步修复 : 这个是最常用的方式，通过定时对账检测副本数据的一致性，并修复。

# 高并发系统的设计
## 系统拆分
将一个系统拆分为多个子系统，用 RPC 来搞。然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，不也可以扛高并发么。
## 缓存
大部分的高并发场景，都是读多写少，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟 Redis 轻轻松松单机几万的并发。所以你可以考虑
考虑你的项目里，那些承载主要请求的读场景，怎么用缓存来抗高并发。
## 消息队列
可能你还是会出现高并发写的场景，比如说一个业务操作里要频繁搞数据库几十次，增删改增删改。那高并发绝对搞挂你的系统，你要是用 Redis 来承载写那肯定不行，人家
是缓存，数据随时就被 LRU 了，数据格式还无比简单，没有事务支持。所以该用 MySQL 还得用 MySQL 啊。那你咋办？用 MQ 吧，大量的写请求灌入 MQ 里，后边系统消费
后慢慢写，控制在 MySQL 承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。
## 分库分表
分库分表，可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表拆分为多个表，每个表的
数据量保持少一点，提高 SQL 跑的性能。
## 读写分离
读写分离，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，主库写入，从库读取，搞一个读写分离。读流量太多
的时候，还可以加更多的从库。

# 分布式
## 分布式缓存
1. 应用场景
1. 缓存雪崩
1. 缓存穿透
1. 缓存预热
1. 缓存更新
1. 缓存降级
## 分布式锁
1. Redis的RedLock锁
如果对性能要求比较高的话，建议使用 Redis 实现分布式锁。推荐优先选择 Redisson 提供的现成分布式锁，而不是自己实现。实际项目中不建议使用 Redlock 算法，成本和收益不成正比，可以考虑基于 Redis 主从复制+哨兵模式实现分布式锁。

1. 基于ZooKeeper的分布式锁
如果对可靠性要求比较高，建议使用 ZooKeeper 实现分布式锁，推荐基于 Curator 框架来实现。不过，现在很多项目都不会用到 ZooKeeper，如果单纯是因为分布式锁而引入 ZooKeeper 的话，那是不太可取的，不建议这样做，为了一个小小的功能增加了系统的复杂度。
## 分布式事务
1. 2PCI/XA方案
1. TCC强一致性方案
1. 可靠消息最终一致性方案✔️
1. 最大努力通知方案✔️

---
# Q
## 如何保证缓存和数据库数据的一致性？
引入缓存之后，如果为了短时间的不一致性问题，选择让系统设计变得更加复杂的话，完全没必要。下面单独对 Cache Aside Pattern（旁路缓存模式） 来聊聊。

Cache Aside Pattern 中遇到写请求是这样的：更新数据库，然后直接删除缓存 。如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说有两个解决方案：

- 缓存失效时间变短（不推荐，治标不治本）：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。
- 增加缓存更新重试机制（常用）：如果缓存服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。不过，这里更适合引入消息队列实现异步重试，将删除缓存重试的消息投递到消息队列，然后由专门的消费者来重试，直到成功。虽然说多引入了一个消息队列，但其整体带来的收益还是要更高一些。

## 如何实现一致性？

1. **分布式事务**：
   - 使用 **两阶段提交（2PC）** 或 **三阶段提交（3PC）** 协议来保证跨多个节点的事务一致性。
   - 采用 **补偿事务** 来处理失败的事务，确保系统最终达到一致状态。

1. **锁机制**：
   - 使用 **乐观锁** 和 **悲观锁** 来控制对共享资源的访问，防止数据冲突。
   - 实现 **分布式锁**（如 Zookeeper、Redis 等）来协调多个服务实例间的访问。

1. **版本控制**：
   - 通过维护数据的版本号，确保在更新数据时能够检测到并发修改，从而避免数据不一致。

1. **数据复制**：
   - 使用 **主从复制** 或 **多主复制** 来保持不同节点间的数据一致性。
   - 采用 **日志复制** 或 **事件源** 来确保数据在不同节点间的一致性。

1. **一致性哈希**：
   - 在分布式系统中使用一致性哈希算法来均匀分配负载，确保数据在节点间的均匀分布和快速路由。

1. **冲突解决策略**：
   - 在最终一致性模型下，设计冲突解决策略，例如 **最后写入胜出**、**合并策略** 等，以处理并发写入导致的数据冲突。

1. **监控与审计**：
   - 实现监控系统，及时发现和处理一致性问题。
   - 记录操作日志，便于回溯和审计，确保数据的可追溯性。

## 实现一致性示例
### 统一递交
山河图体力重置,修改数据都要由actserver来做，保证数据一致性
```cpp
UserRogueLikeAct.cpp 
void CUserRogueLikeAct::check_clear_data(unsigned int time)

roguelike::RogueLikeWorkNtf ntf;
ntf.set_type(roguelike::kWorkDailyReset);
auto pAct = DBSNetMg::single().find_session_rand_loadfactor_server(eActRogueServer);
if (pAct)
{
    NetMsgHandleModule::SendNetMsg(pAct->GetConID(), SS_ROGUELIKE_WORK_NTF, ntf, m_pUser->get_temp_id(), 0);
}
```

### 日志回溯
- 检查数据库返回的数据是否与请求中的数据一致。如果不一致，设置msg.result表示创建角色请求的返回结果的错误原因。
- 记录操作日志，便于回溯和审计，确保数据的可追溯性。
```cpp
DbManager.cpp 
void CDbManager::Imp_CreateRole(CsqlstringRequest *pRequest,const ClientMsgCreateRoleReq *pCopyRoleReqMsg)

string nickname(pQtNewNK->tbl_nickname);
if (nickname != string(pCopyRoleReqMsg->Nickname) || nickname.size() >= sc_max_nickname_len)
{
	IsHaveError     = true;
	APPLOG_ERROR( "[创建昵称失败] db返回的昵称和请求消息包的数据不一致! account="<<pQtNewNK->req_create_account<<";tbl_nickname="<<pQtNewNK->tbl_nickname<<";Nickname="<<pCopyRoleReqMsg->Nickname);
	msg.result		= TResult_CreateRoleReq::ret_creatrole_dberror_nickname_matchingerror;
	return;
}
```

### 冲突避免
- 使用`CHelpAutoSendMsg`类创建一个自动发送消息的对象`autosendmsg`，将`conId`和`repMsg`作为参数传递
- 操作铜钱之前，比对pUser->get_tongqian() != pMsg->curtotaltongqian操作后再进行后续处理
```cpp
dbs_msg_gameserver.cpp 
void DBSNetMg::NetMsgSsDbsTongqianConsumeReq( unsigned int conId, const SsDbsTongqianConsumeReq* pMsg )

CHelpAutoSendMsg autosendmsg( conId,&repMsg );
APPLOG_SYSINFO("[操作铜钱] account="<<pUser->getaccount()<<";dbstongqina="<<pUser->get_tongqian()<<";type="<<pMsg->type<<";msgtongqian="<<pMsg->optongqiancount );
if( pUser->get_tongqian() != pMsg->curtotaltongqian )
{
	APPLOG_ERROR("[操作铜钱.铜钱不一致] account="<<pUser->getaccount()<<";dbstongqina="<<pUser->get_tongqian()<<";msgtongqian="<<pMsg->curtotaltongqian<<FUN_FILE_LINE );
}
```

